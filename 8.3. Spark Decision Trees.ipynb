{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uGppQZgrc1DS",
    "outputId": "9888d65e-4434-45bd-a5ee-fd67af7773d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /usr/local/spark/python (3.5.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.11/site-packages (from pyspark) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "DQxT91fDc4ng"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Duav-SQ1c-Rt"
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"DecisionTreeExample\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nT-Kp9oPdtdr"
   },
   "source": [
    "Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "0fdg-H5zdeAA"
   },
   "outputs": [],
   "source": [
    "data = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"realestate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AMu_9uV0d2oZ",
    "outputId": "4642a70a-35b4-48c0-be0c-5560876dc9f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+--------+-------------+-----------------------+--------+---------+---------------+\n",
      "| No|TransactionDate|HouseAge|DistanceToMRT|NumberConvenienceStores|Latitude|Longitude|PriceOfUnitArea|\n",
      "+---+---------------+--------+-------------+-----------------------+--------+---------+---------------+\n",
      "|  1|       2012.917|    32.0|     84.87882|                     10|24.98298|121.54024|           37.9|\n",
      "|  2|       2012.917|    19.5|     306.5947|                      9|24.98034|121.53951|           42.2|\n",
      "+---+---------------+--------+-------------+-----------------------+--------+---------+---------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below step is creating a new column called features, which will be a vector that contains all the values from the specified columns (\"HouseAge\", \"DistanceToMRT\", \"NumberConvenienceStores\", \"Latitude\", \"Longitude\"). This feature vector can then be used as input for machine learning models in PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "6tZm2Iopdva7"
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler().setInputCols([\"HouseAge\", \"DistanceToMRT\", \"NumberConvenienceStores\", \"Latitude\", \"Longitude\"]).setOutputCol(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "cRCUSShJeJ7J"
   },
   "outputs": [],
   "source": [
    "df = assembler.transform(data).select(\"PriceOfUnitArea\", \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[PriceOfUnitArea: double, features: vector]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "V8namFupeeAy"
   },
   "outputs": [],
   "source": [
    "trainTest = df.randomSplit([0.8,0.2])\n",
    "trainDF = trainTest[0]\n",
    "testDF = trainTest[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0qLjUyyetxF"
   },
   "source": [
    "Initialize DecisionTreeRegressor:\n",
    "\n",
    "From https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.DecisionTreeRegressor.html:\n",
    "\n",
    "class pyspark.ml.regression.DecisionTreeRegressor(*, featuresCol: str = 'features', labelCol: str = 'label', predictionCol: str = 'prediction', maxDepth: int = 5, maxBins: int = 32, minInstancesPerNode: int = 1, minInfoGain: float = 0.0, maxMemoryInMB: int = 256, cacheNodeIds: bool = False, checkpointInterval: int = 10, impurity: str = 'variance', seed: Optional[int] = None, varianceCol: Optional[str] = None, weightCol: Optional[str] = None, leafCol: str = '', minWeightFractionPerNode: float = 0.0)[source]Â¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "D0NSxV4Ueg9Y"
   },
   "outputs": [],
   "source": [
    "spark_DecisionTree = DecisionTreeRegressor(featuresCol = 'features', labelCol='PriceOfUnitArea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "hNBCnecBfGJf"
   },
   "outputs": [],
   "source": [
    "model = spark_DecisionTree.fit(trainDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets perform test and cache the result\n",
    "\n",
    "By caching the DataFrame, you store the results of the transformation (in this case, the predictions) in memory. This avoids recomputing the same DataFrame multiple times, saving time and resources, especially when the transformations are complex or when the data is large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "P1qp3bpCfM1G"
   },
   "outputs": [],
   "source": [
    "predictions = model.transform(testDF).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jD3HplMEfSvR",
    "outputId": "da8c8c85-0bea-4bfd-87fb-1ee01d3ad886"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+------------------+\n",
      "|PriceOfUnitArea|            features|        prediction|\n",
      "+---------------+--------------------+------------------+\n",
      "|           11.6|[16.0,4066.587,0....|15.809999999999999|\n",
      "|           15.5|[26.9,4449.27,0.0...|18.883333333333333|\n",
      "|           15.6|[25.6,4519.69,0.0...|18.883333333333333|\n",
      "|           16.1|[31.9,1146.329,0....|13.433333333333335|\n",
      "|           17.4|[27.1,4412.765,1....|18.883333333333333|\n",
      "+---------------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YjJ6INkJgNdJ"
   },
   "source": [
    "We convert to rdd as they are easy to deal with while extarcting values compared to dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "XZNQCutRfgQf"
   },
   "outputs": [],
   "source": [
    "predicted_values = predictions.select(\"prediction\").rdd.map(lambda x:x[0])\n",
    "label_values = predictions.select(\"PriceOfUnitArea\").rdd.map(lambda x:x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "C3ZDCxthf0js"
   },
   "outputs": [],
   "source": [
    "predicted_values_and_labels = predicted_values.zip(label_values).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eeysLcNmf7RV",
    "outputId": "41f07dc2-492f-4c94-c689-e2d70ddbc927"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15.809999999999999, 11.6)\n",
      "(18.883333333333333, 15.5)\n",
      "(18.883333333333333, 15.6)\n",
      "(13.433333333333335, 16.1)\n",
      "(18.883333333333333, 17.4)\n",
      "(15.809999999999999, 20.5)\n",
      "(26.26271186440678, 20.7)\n",
      "(26.26271186440678, 20.9)\n",
      "(21.2, 22.3)\n",
      "(26.26271186440678, 22.9)\n",
      "(38.071052631578944, 23.0)\n",
      "(26.26271186440678, 23.1)\n",
      "(21.2, 23.1)\n",
      "(26.26271186440678, 23.5)\n",
      "(26.26271186440678, 24.7)\n",
      "(40.55178571428572, 25.0)\n",
      "(26.26271186440678, 25.9)\n",
      "(26.26271186440678, 26.5)\n",
      "(26.26271186440678, 27.0)\n",
      "(26.26271186440678, 27.7)\n",
      "(26.26271186440678, 28.6)\n",
      "(38.071052631578944, 28.8)\n",
      "(35.160000000000004, 29.3)\n",
      "(38.071052631578944, 29.7)\n",
      "(26.26271186440678, 30.7)\n",
      "(38.071052631578944, 30.9)\n",
      "(26.26271186440678, 31.1)\n",
      "(26.26271186440678, 31.3)\n",
      "(31.814285714285713, 34.0)\n",
      "(38.071052631578944, 34.1)\n",
      "(40.55178571428572, 34.2)\n",
      "(28.9375, 34.3)\n",
      "(31.814285714285713, 34.6)\n",
      "(40.55178571428572, 35.3)\n",
      "(40.55178571428572, 35.5)\n",
      "(40.55178571428572, 37.4)\n",
      "(40.55178571428572, 37.5)\n",
      "(38.071052631578944, 40.1)\n",
      "(40.55178571428572, 40.3)\n",
      "(38.071052631578944, 40.5)\n",
      "(44.16666666666668, 40.8)\n",
      "(38.071052631578944, 41.4)\n",
      "(45.821875000000006, 42.0)\n",
      "(45.821875000000006, 42.2)\n",
      "(38.071052631578944, 42.5)\n",
      "(35.160000000000004, 42.9)\n",
      "(54.425925925925924, 43.1)\n",
      "(45.821875000000006, 44.3)\n",
      "(48.08636363636364, 45.1)\n",
      "(54.425925925925924, 45.2)\n",
      "(45.821875000000006, 46.0)\n",
      "(45.821875000000006, 46.1)\n",
      "(45.821875000000006, 46.6)\n",
      "(40.55178571428572, 46.6)\n",
      "(45.821875000000006, 47.1)\n",
      "(40.55178571428572, 47.3)\n",
      "(38.071052631578944, 48.0)\n",
      "(35.160000000000004, 48.2)\n",
      "(48.08636363636364, 48.6)\n",
      "(54.425925925925924, 49.5)\n",
      "(54.425925925925924, 50.4)\n",
      "(48.08636363636364, 51.6)\n",
      "(48.08636363636364, 51.8)\n",
      "(44.13333333333333, 52.2)\n",
      "(54.425925925925924, 52.7)\n",
      "(45.821875000000006, 53.0)\n",
      "(54.425925925925924, 53.9)\n",
      "(51.925, 54.4)\n",
      "(45.821875000000006, 55.0)\n",
      "(45.821875000000006, 55.9)\n",
      "(51.925, 57.8)\n",
      "(54.425925925925924, 58.0)\n",
      "(54.425925925925924, 58.8)\n",
      "(54.425925925925924, 59.0)\n",
      "(45.821875000000006, 59.6)\n",
      "(51.925, 62.1)\n",
      "(67.7, 71.0)\n",
      "(67.7, 73.6)\n",
      "(54.13333333333334, 78.3)\n",
      "(35.160000000000004, 117.5)\n"
     ]
    }
   ],
   "source": [
    "for prediction in predicted_values_and_labels:\n",
    "  print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "XilAWimCgXGM"
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ND81j8R3geWm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
